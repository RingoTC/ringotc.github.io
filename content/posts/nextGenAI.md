+++
title = 'LLM的智能是否还会持续增长？'
date = 2025-02-03T13:21:14-08:00
draft = true
+++

> 💭
> 英伟达的股票在接近两年的暴涨之后迎来首次的暴跌，这是否预示着本轮人工智能的热度已经达到顶点？

本轮人工智能大家一般是指基于大语言模型（Large Language Model, LLM）的技术浪潮。据我所知，最早用生成作为统一范式来解决不同任务的是 Google 在 2018年发表的 Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer，提出了 T5 模型。

![Google T5 Model](/google-t5.png)

*图 1：Google T5 模型的示意图。*

从这张图里就能看出，Google T5 已经开始触及 Prompt Learning。我在 Google T5 发布之初就接触到这份工作，当时唯一的想法是感叹 Google T5 的参数量之大（Google T5: 11B; BERT-base: 0.11B），并没有对这种基于生成模型解决下游任务的做法有太大的认同。这是因为，我认为除了翻译、总结、改写这种本身就是生成的任务，其他的，如文本分类、实体识别等当时学术界更关心的任务并没看到更明显的优势。因为纯 Transformer，很难通过模型结构的设计把人类知识注入进去。

学术界和工业界在这个问题上也大多保持这样的看法，因此可以看到很多厂商在做了 ERINE、ALBERT 等模型之后，对预训练模型的研发上停下来了。包括 Google 自己，也并没有沿着 T5 这条路继续探索生成模型的上限。

这件事情直到 ChatGPT 的问世。

![ChatGPT](/chatGPT.avif)

*图 2：ChatGPT 的示意图。*

ChatGPT 创造性地提出了用强化学习去让语言模型对齐人类认知的方法，并且在模型智能上有非常大的飞跃。实际上除了少部分生成任务的研究者，大部分 NLP 研究者对 GPT 这种生成模型的关注是远不如 BERT 这样判别模型的关注，原因则是上文已经提及的，大家更关心的是判别任务而 GPT 系列模型在这个任务上比 BERT 并没有太大优势。ChatGPT 的问世像一道惊雷，让大家突然意识到 GPT 模型的先进。

> 😂
> 第一次用 ChatGPT 的时候，和身边很多朋友聊到这个模型，大家的态度都是怀疑偏多。这是因为当时学界最先进的生成模型，连生成一个没有语病的句子、能让模型停下来都很难做到，更别说真正的智能了。

所谓停不下来的问题是指，生成模型会反复重复自己之前说过的话。语病、让模型停下来、如何注入逻辑与外部知识...学界提出了很多解决方案来解决这些问题，然而这些方案绝大部分都没有能够实装到工业模型里去，这里存在巨大的学界和工业界的 GAP，总的来说是工业界真的看不上这些东西。

![Deepseek](/deepseek-stop.png)

*图 3：Deepseek 的最新模型似乎重新遇到了停不下来的问题*

ChatGPT 的发布让大家发现，只要我把模型的参数量做得更大，真的就不容易出现语法错误，也不容易出现停不下来的问题。**给小模型屎上雕花，远不如把模型做得更大，力大飞砖是真的有用**。

接下来的故事就是大家如何用各种各样的设计去让模型参数量不断往上走，也的确参数量增大之后模型的智能有显著提升。

但我却并不这样想。

> ✨
> 在 ChatGPT 发布之初，我有一个想法。我认为 ChatGPT 的智能真正来自 RLHF 而不是 GPT3.5这个基座模型。这是因为 GPT3 和 GPT3.5 的模型参数量并没有太大提升，模型结构设计也没有明显变化（直到今天，模型的结构也依旧是Transformer Encoder，只是在计算和存储效率上有所改进）。而 RLHF 这件事情是不太容易 scale up 上去的。

![GPTv4 Compare](/gptv4.png)

*图 4：gpt-4 在 zero-shot, base 和 RLHF 下的不同表现*

*图 4* 是 OpenAI 在发表 GPT4 时做的实验，发现在 TruthfulQA 上，GPT4 和 GPT3.5 性能不存在明显差异，RLHF 之后性能得到交大提升。

